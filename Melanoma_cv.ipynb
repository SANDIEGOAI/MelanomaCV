{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3ws0Hx-NeBK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install Libraries & Import Modules\n",
        "!pip install -q segmentation-models-pytorch\n",
        "!pip install -q albumentations==1.3.1\n",
        "!pip install -q torchinfo\n",
        "!pip install -q grad-cam\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import torchvision.models as models\n",
        "import segmentation_models_pytorch as smp\n",
        "import albumentations as A\n",
        "import glob\n",
        "import shutil\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
        "import seaborn as sns\n",
        "\n",
        "# Setup Device (GPU)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"âœ… Environment Ready! Using Device: {device}\")"
      ],
      "metadata": {
        "id": "3T-OBHNYOMVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Download & Fix Data\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Clean Slate (Remove old data to prevent conflicts)\n",
        "for folder in ['/content/seg_data', '/content/cls_data']:\n",
        "    if os.path.exists(folder):\n",
        "        shutil.rmtree(folder)\n",
        "\n",
        "# 2. Upload kaggle.json if missing\n",
        "if not os.path.exists('kaggle.json'):\n",
        "    print(\"Please upload your kaggle.json file now...\")\n",
        "    files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"ðŸš€ Downloading Datasets...\")\n",
        "\n",
        "# --- A. SEGMENTATION DATA (ISIC 2016) ---\n",
        "!kaggle datasets download -d santiagodelrey/isic-2016-task-1-training-data -p /content/seg_data --unzip\n",
        "\n",
        "# --- B. CLASSIFICATION DATA (ISIC 2019 Resized) ---\n",
        "!kaggle datasets download -d nischaydnk/isic-2019-jpg-224x224-resized -p /content/cls_data --unzip\n",
        "\n",
        "# --- C. METADATA FIX (Official CSV) ---\n",
        "# Force download the correct metadata to fix the \"KeyError\"\n",
        "!kaggle datasets download -d andrewmvd/isic-2019 -f ISIC_2019_Training_Metadata.csv -p /content/cls_data --unzip\n",
        "\n",
        "print(\"âœ… Data Download Complete!\")"
      ],
      "metadata": {
        "id": "bTlEo1XYOMYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Stage 1 Data Setup\n",
        "def find_isic2016_folders(base_path):\n",
        "    img_files = glob.glob(f\"{base_path}/**/*.jpg\", recursive=True)\n",
        "    mask_files = glob.glob(f\"{base_path}/**/*.png\", recursive=True)\n",
        "    return os.path.dirname(img_files[0]), os.path.dirname(mask_files[0])\n",
        "\n",
        "SEG_IMG_DIR, SEG_MASK_DIR = find_isic2016_folders('/content/seg_data')\n",
        "\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, img_dir, mask_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.images = [f for f in os.listdir(img_dir) if f.endswith('.jpg')]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.images[idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        # ISIC 2016 Mask Naming Logic\n",
        "        mask_name = img_name.replace('.jpg', '_Segmentation.png')\n",
        "        mask_path = os.path.join(self.mask_dir, mask_name)\n",
        "\n",
        "        if not os.path.exists(mask_path): # Fallback\n",
        "            mask_name = img_name.replace('.jpg', '.png')\n",
        "            mask_path = os.path.join(self.mask_dir, mask_name)\n",
        "\n",
        "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        try:\n",
        "            mask = np.array(Image.open(mask_path).convert(\"L\"))\n",
        "        except:\n",
        "            mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
        "\n",
        "        mask = mask / 255.0\n",
        "        mask = np.expand_dims(mask, axis=-1)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "\n",
        "        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
        "        mask = torch.tensor(mask, dtype=torch.float32).permute(2, 0, 1)\n",
        "        return image, mask\n",
        "\n",
        "seg_transform = A.Compose([A.Resize(256, 256), A.HorizontalFlip(p=0.5), A.Rotate(limit=20, p=0.5)])\n",
        "seg_dataset = SegmentationDataset(SEG_IMG_DIR, SEG_MASK_DIR, seg_transform)\n",
        "seg_loader = DataLoader(seg_dataset, batch_size=16, shuffle=True)\n",
        "print(f\"âœ… Stage 1 Ready: {len(seg_dataset)} segmentation images.\")"
      ],
      "metadata": {
        "id": "9WwU9tf8OMwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qw2kiJGf6vVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Train U-Net\n",
        "unet_model = smp.Unet(encoder_name=\"resnet34\", encoder_weights=\"imagenet\", in_channels=3, classes=1, activation=None).to(device)\n",
        "optimizer = torch.optim.Adam(unet_model.parameters(), lr=0.0001)\n",
        "criterion = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "\n",
        "print(\"ðŸš€ Training Segmentation Model...\")\n",
        "unet_model.train()\n",
        "for epoch in range(8): # Train 8 epochs\n",
        "    total_loss = 0\n",
        "    for images, masks in seg_loader:\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(unet_model(images), masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1} | Dice Loss: {total_loss/len(seg_loader):.4f}\")\n",
        "\n",
        "# Save\n",
        "torch.save(unet_model.state_dict(), \"unet_model.pth\")"
      ],
      "metadata": {
        "id": "G4r94cVt6vYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Je6GiyIH6vbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Stage 2 Data Setup (Fusion)\n",
        "# 1. Merge Metadata\n",
        "print(\"Merging Metadata...\")\n",
        "df_main = pd.read_csv('/content/cls_data/train-metadata.csv')\n",
        "# Handle encoding issues automatically\n",
        "try:\n",
        "    df_meta = pd.read_csv('/content/cls_data/ISIC_2019_Training_Metadata.csv')\n",
        "except:\n",
        "    df_meta = pd.read_csv('/content/cls_data/ISIC_2019_Training_Metadata.csv', encoding='latin1')\n",
        "\n",
        "df = df_main.merge(df_meta, left_on='isic_id', right_on='image', how='inner')\n",
        "print(f\"Merged Dataset Size: {len(df)}\")\n",
        "\n",
        "# 2. Define Fusion Dataset\n",
        "class FusionDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, unet_model=None, transform=None):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.unet = unet_model\n",
        "\n",
        "    def __len__(self): return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_name = row['isic_id'] + '.jpg'\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "        except:\n",
        "            return self.__getitem__((idx + 1) % len(self.df))\n",
        "\n",
        "        # STAGE 1: Apply Segmentation Mask\n",
        "        if self.unet:\n",
        "            with torch.no_grad():\n",
        "                u_in = T.Compose([T.Resize((256, 256)), T.ToTensor()])(image).unsqueeze(0).to(device)\n",
        "                mask = (self.unet(u_in).sigmoid() > 0.5).float()\n",
        "                image = T.ToPILImage()( (u_in * mask).squeeze().cpu() )\n",
        "\n",
        "        # STAGE 2: Metadata Processing\n",
        "        age = float(row['age_approx']) / 100.0 if pd.notna(row['age_approx']) else 0.5\n",
        "        sex = 1.0 if row['sex'] == 'female' else 0.0\n",
        "        site = 1.0 if 'torso' in str(row['anatom_site_general']).lower() else 0.0\n",
        "        meta = torch.tensor([age, sex, site], dtype=torch.float32)\n",
        "\n",
        "        label = torch.tensor(row['target'], dtype=torch.float32)\n",
        "        if self.transform: image = self.transform(image)\n",
        "        return image, meta, label\n",
        "\n",
        "CLS_IMG_DIR = '/content/cls_data/train-image/image'\n",
        "cls_transform = T.Compose([T.Resize((224, 224)), T.ToTensor(), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "fusion_dataset = FusionDataset(df, CLS_IMG_DIR, unet_model=unet_model, transform=cls_transform)\n",
        "fusion_loader = DataLoader(fusion_dataset, batch_size=32, shuffle=True)\n",
        "print(\"âœ… Fusion Dataset Ready!\")"
      ],
      "metadata": {
        "id": "xKANXmwt6vdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aPq0TYXs6vgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Train Fusion Model\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
        "    def forward(self, inputs, targets):\n",
        "        bce_loss = self.bce(inputs, targets)\n",
        "        pt = torch.exp(-bce_loss)\n",
        "        return (self.alpha * (1 - pt) ** self.gamma * bce_loss).mean()\n",
        "\n",
        "class MelanomaFusionNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.effnet = models.efficientnet_b0(weights='DEFAULT')\n",
        "        self.effnet.classifier = nn.Identity()\n",
        "        self.meta_net = nn.Sequential(nn.Linear(3, 16), nn.ReLU(), nn.Linear(16, 16), nn.ReLU())\n",
        "        self.classifier = nn.Sequential(nn.Linear(1280 + 16, 128), nn.ReLU(), nn.Dropout(0.4), nn.Linear(128, 1))\n",
        "    def forward(self, image, meta):\n",
        "        return self.classifier(torch.cat((self.effnet(image), self.meta_net(meta)), dim=1))\n",
        "\n",
        "model = MelanomaFusionNet().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = FocalLoss()\n",
        "\n",
        "print(\"ðŸš€ Training Fusion Model (This takes ~15 mins)...\")\n",
        "model.train()\n",
        "for epoch in range(5):\n",
        "    total_loss = 0\n",
        "    for images, meta, labels in fusion_loader:\n",
        "        images, meta, labels = images.to(device), meta.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(images, meta).squeeze(), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1} | Focal Loss: {total_loss/len(fusion_loader):.4f}\")"
      ],
      "metadata": {
        "id": "mpeKDvIZ6vic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PZ_ajKBq6vlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Evaluation\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "# 1. Metrics\n",
        "print(\"Running Evaluation...\")\n",
        "model.eval()\n",
        "test_loader = DataLoader(FusionDataset(df.iloc[-1000:], CLS_IMG_DIR, unet_model, cls_transform), batch_size=32)\n",
        "all_preds, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for img, meta, lbl in test_loader:\n",
        "        out = model(img.to(device), meta.to(device)).squeeze()\n",
        "        all_preds.extend(torch.sigmoid(out).cpu().numpy())\n",
        "        all_labels.extend(lbl.numpy())\n",
        "\n",
        "roc = roc_auc_score(all_labels, all_preds)\n",
        "print(f\"ðŸ† Final AUC-ROC: {roc:.4f}\")\n",
        "\n",
        "# 2. Plotting\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
        "cm = confusion_matrix(all_labels, [1 if p > 0.5 else 0 for p in all_preds])\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax[0]); ax[0].set_title(\"Confusion Matrix\")\n",
        "fpr, tpr, _ = roc_curve(all_labels, all_preds)\n",
        "ax[1].plot(fpr, tpr); ax[1].set_title(\"ROC Curve\"); plt.show()\n",
        "\n",
        "# 3. Grad-CAM (Before vs After)\n",
        "print(\"Generating Heatmaps...\")\n",
        "class Wrapper(nn.Module):\n",
        "    def __init__(self, m): super().__init__(); self.m = m\n",
        "    def forward(self, x): return self.m(x, torch.zeros(x.size(0), 3).to(device))\n",
        "\n",
        "cam = GradCAM(model=Wrapper(model), target_layers=[model.effnet.features[-1]])\n",
        "ds_clean = FusionDataset(df, CLS_IMG_DIR, unet_model, cls_transform)\n",
        "ds_raw = FusionDataset(df, CLS_IMG_DIR, None, cls_transform) # No U-Net\n",
        "\n",
        "idx = 5 # Sample index\n",
        "img_clean, _, _ = ds_clean[idx]\n",
        "img_raw, _, _ = ds_raw[idx]\n",
        "\n",
        "hm = cam(input_tensor=img_clean.unsqueeze(0).to(device), targets=None)[0, :]\n",
        "rgb = img_clean.permute(1, 2, 0).cpu().numpy()\n",
        "rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min())\n",
        "vis = show_cam_on_image(rgb, hm, use_rgb=True)\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "ax[0].imshow(img_raw.permute(1, 2, 0).cpu().numpy()); ax[0].set_title(\"Raw Input\")\n",
        "ax[1].imshow(rgb); ax[1].set_title(\"Segmented Input\")\n",
        "ax[2].imshow(vis); ax[2].set_title(\"Model Attention\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7KzQX31Q6vnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G2RjXoXV6vqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Save to Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_path = '/content/drive/MyDrive/MelanomaProject/models'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "torch.save(unet_model.state_dict(), f\"{save_path}/stage1_unet.pth\")\n",
        "torch.save(model.state_dict(), f\"{save_path}/stage2_fusion.pth\")\n",
        "print(f\"âœ… Models saved to {save_path}\")"
      ],
      "metadata": {
        "id": "lv983iyO6vsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YdEdtGXM6v2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lS_Qs9Rd6v5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "import torchvision.models as models\n",
        "import segmentation_models_pytorch as smp\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# 2. Setup Device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# 3. Re-Define the Fusion Model Architecture (Must match training exactly)\n",
        "class MelanomaFusionNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MelanomaFusionNet, self).__init__()\n",
        "        # Image Branch\n",
        "        self.effnet = models.efficientnet_b0(weights=None) # No weights needed, we load ours\n",
        "        self.effnet.classifier = nn.Identity()\n",
        "        # Meta Branch\n",
        "        self.meta_net = nn.Sequential(nn.Linear(3, 16), nn.ReLU(), nn.Linear(16, 16), nn.ReLU())\n",
        "        # Fusion Head\n",
        "        self.classifier = nn.Sequential(nn.Linear(1280 + 16, 128), nn.ReLU(), nn.Dropout(0.4), nn.Linear(128, 1))\n",
        "\n",
        "    def forward(self, image, meta):\n",
        "        return self.classifier(torch.cat((self.effnet(image), self.meta_net(meta)), dim=1))\n",
        "\n",
        "print(\"âœ… Model Architectures Defined.\")"
      ],
      "metadata": {
        "id": "T87gi4av6v-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "agfmCMUu6wBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. Mount Drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define Paths (Adjust if your folder name is different)\n",
        "SAVE_PATH = '/content/drive/MyDrive/MelanomaProject/models'\n",
        "UNET_PATH = os.path.join(SAVE_PATH, 'stage1_unet.pth') # Or 'stage1_unet_final.pth'\n",
        "FUSION_PATH = os.path.join(SAVE_PATH, 'stage2_fusion.pth') # Or 'stage2_fusion_final.pth'\n",
        "\n",
        "# 3. Load Stage 1: U-Net\n",
        "print(\"Loading U-Net...\")\n",
        "unet = smp.Unet(encoder_name=\"resnet34\", in_channels=3, classes=1, activation=None).to(device)\n",
        "try:\n",
        "    unet.load_state_dict(torch.load(UNET_PATH, map_location=device))\n",
        "    unet.eval() # Set to evaluation mode (freezes dropout/batchnorm)\n",
        "    print(\"âœ… U-Net Loaded!\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"âŒ Error: Could not find {UNET_PATH}. Check your Drive folder.\")\n",
        "\n",
        "# 4. Load Stage 2: Fusion Model\n",
        "print(\"Loading Fusion Model...\")\n",
        "model = MelanomaFusionNet().to(device)\n",
        "try:\n",
        "    model.load_state_dict(torch.load(FUSION_PATH, map_location=device))\n",
        "    model.eval()\n",
        "    print(\"âœ… Fusion Model Loaded!\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"âŒ Error: Could not find {FUSION_PATH}. Check your Drive folder.\")"
      ],
      "metadata": {
        "id": "OJzfS9wB6wEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PCsK5O16IXbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_melanoma(image_path, age=50, sex='male', site='torso'):\n",
        "    \"\"\"\n",
        "    Full Pipeline: Raw Image -> U-Net Mask -> Crop -> Fusion Model -> Diagnosis\n",
        "    \"\"\"\n",
        "    # --- PREPROCESS METADATA ---\n",
        "    # Normalize inputs exactly like training\n",
        "    age_norm = float(age) / 100.0\n",
        "    sex_norm = 1.0 if sex.lower() == 'female' else 0.0\n",
        "    site_norm = 1.0 if site.lower() in ['torso', 'anterior torso', 'posterior torso'] else 0.0\n",
        "\n",
        "    meta_tensor = torch.tensor([[age_norm, sex_norm, site_norm]], dtype=torch.float32).to(device)\n",
        "\n",
        "    # --- LOAD IMAGE ---\n",
        "    try:\n",
        "        raw_img = Image.open(image_path).convert(\"RGB\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening image: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- STAGE 1: SEGMENTATION ---\n",
        "    # Resize to 256 for U-Net\n",
        "    unet_transform = T.Compose([T.Resize((256, 256)), T.ToTensor()])\n",
        "    unet_input = unet_transform(raw_img).unsqueeze(0).to(device) # Add batch dim\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mask_logits = unet(unet_input)\n",
        "        mask = (mask_logits.sigmoid() > 0.5).float()\n",
        "\n",
        "    # Apply Mask (Black out background)\n",
        "    masked_tensor = unet_input * mask\n",
        "    masked_pil = T.ToPILImage()(masked_tensor.squeeze().cpu())\n",
        "\n",
        "    # --- STAGE 2: CLASSIFICATION ---\n",
        "    # Resize to 224 for EfficientNet + Normalize\n",
        "    cls_transform = T.Compose([\n",
        "        T.Resize((224, 224)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    cls_input = cls_transform(masked_pil).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(cls_input, meta_tensor)\n",
        "        prob = torch.sigmoid(output).item()\n",
        "\n",
        "    # --- VISUALIZATION ---\n",
        "    prediction = \"MALIGNANT (Cancer)\" if prob > 0.5 else \"BENIGN (Safe)\"\n",
        "    color = \"red\" if prob > 0.5 else \"green\"\n",
        "\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # 1. Raw\n",
        "    ax[0].imshow(raw_img)\n",
        "    ax[0].set_title(\"1. Uploaded Image\")\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    # 2. Mask (What the U-Net saw)\n",
        "    ax[1].imshow(mask.squeeze().cpu(), cmap='gray')\n",
        "    ax[1].set_title(\"2. Lesion Mask (Stage 1)\")\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    # 3. Segmented (What the Classifier saw)\n",
        "    ax[2].imshow(masked_pil)\n",
        "    ax[2].set_title(f\"3. Result: {prediction}\\nProbability: {prob:.2%}\", color=color, fontsize=12, fontweight='bold')\n",
        "    ax[2].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "    return prob"
      ],
      "metadata": {
        "id": "45PekNdfIXdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X5U4dSsyIXgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Upload an image to test (jpg/png)...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"\\nProcessing {filename}...\")\n",
        "\n",
        "    # Run the Pipeline\n",
        "    # You can change the patient details here to see how it affects the result!\n",
        "    predict_melanoma(\n",
        "        image_path=filename,\n",
        "        age=45,          # e.g., 45 years old\n",
        "        sex='male',      # 'male' or 'female'\n",
        "        site='torso'     # 'torso' or 'other'\n",
        "    )"
      ],
      "metadata": {
        "id": "UEK5FUZEI9dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z0yWmlJjI9f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CquYShrMI9ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DfJiORloI9k5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TY-_6unFI9my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F5g37N6BIXjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qo-h5pxZ6wGb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}